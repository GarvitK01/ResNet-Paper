{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Dense, BatchNormalization, Flatten, Input, Add\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Identity Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identity block is used when the input and output have the same dimensions\n",
    "<br>The identity block has 3 parts\n",
    "\n",
    "1.  1. 2D Covolution : f1  `(1, 1)` filters with `valid` padding and stride `(1, 1)` \n",
    "    2. Batch Normalization\n",
    "    3. ReLU Non-Linearity \n",
    "    \n",
    "    <br>\n",
    "    \n",
    "2.  1. 2D Covolution : f2  `(f, f)` filters with `same` padding and stride `(1, 1)` \n",
    "    2. Batch Normalization\n",
    "    3. ReLU Non-Linearity\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "3.  1. 2D Convolution : f3  `(1, 1)` filters with `valid` padding and stride `(1, 1)` \n",
    "    2. Batch Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X,  f, filters):\n",
    "    \"\"\"\n",
    "    Identity Block Implementation\n",
    "    \n",
    "    Arguements:\n",
    "    X - input images of shape (N, H, W, C)\n",
    "    f - Shape of filter in the path\n",
    "    filters - list of integers giving the number of filters in different components\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #Shape of filters\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    #Input value for the shortcut path\n",
    "    X_add = X\n",
    "    \n",
    "    \n",
    "    #First component of the identity block\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), padding = 'valid', name = '')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #Second component of the identity block\n",
    "    X = Conv2D(filters = f2, kernel_size = (f, f), padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #Last compenent of the identity block\n",
    "    X = Conv2D(filters = f3, kernel_size = (1, 1), padding = 'valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    # Adding the shortcut to the output\n",
    "    X = Add()([X, X_add])\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Block\n",
    "The convolutional block is used when the input and output dimensions are not the same, so as to adjust the size of the input to match with the output\n",
    "<br> \n",
    "1.  1. 2D Covolution : f1  `(1, 1)` filters with `valid` padding and stride `(1, 1)`\n",
    "    2. Batch Normalization\n",
    "    3. ReLU Non-Linearity \n",
    "    \n",
    "    <br>\n",
    "    \n",
    "2.  1. 2D Covolution : f2  `(f, f)` filters with `same` padding and stride `(1, 1)`\n",
    "    2. Batch Normalization\n",
    "    3. ReLU Non-Linearity\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "3.  1. 2D Convolution : f3  `(1, 1)` filters with `valid` padding and stride `(1, 1)` \n",
    "    2. Batch Normalization\n",
    "    \n",
    "    <br>\n",
    "For the shortcut path :-\n",
    "1.  1. 2D Convolution : f3  `(1, 1)` filters with `valid` padding and stride `(1, 1)` \n",
    "    2. Batch Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X,  f, filters, s = 2):\n",
    "    \"\"\"\n",
    "    Convolutional Block Implementation\n",
    "    \n",
    "    Arguements:\n",
    "    X - input images of shape (N, H, W, C)\n",
    "    f - Shape of filter in the path\n",
    "    filters - list of integers giving the number of filters in different components\n",
    "    s - strides\n",
    "    \"\"\"\n",
    "    \n",
    "    #Shape of filters\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    #Input value for the shortcut path\n",
    "    X_add = X\n",
    "    \n",
    "    \n",
    "    #First component of the identity block\n",
    "    X = Conv2D(filters=f1, kernel_size=(1, 1), padding = 'valid', strides = (s, s))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #Second component of the identity block\n",
    "    X = Conv2D(filters = f2, kernel_size = (f, f), padding = 'same')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #Last compenent of the identity block\n",
    "    X = Conv2D(filters = f3, kernel_size = (1, 1), padding = 'valid')(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    \n",
    "    #Shortcut Path\n",
    "    X_add = Conv2D(filters = f3, kernel_size = (1, 1), padding = 'valid', strides = (s, s))(X_add)\n",
    "    X_add = BatchNormalization()(X_add)\n",
    "    \n",
    "    X = Add()([X_add, X])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(input_shape = (32, 32, 3), num_classes = 10):\n",
    "    \"\"\"\n",
    "    The main ResNet Model\n",
    "    \n",
    "    Arguements:\n",
    "    input_shape : input shape of the image\n",
    "    num_classes : Total number of classes for classification\n",
    "    \"\"\"\n",
    "    #Defining the Input\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(filters = 32, kernel_size = (3, 3))(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides = (1, 1))(X)\n",
    "    \n",
    "    #Using the identity and convolutional blocks\n",
    "    X = convolutional_block(X, 5, [64, 64, 128])\n",
    "    X = identity_block(X, 3, [64, 64, 128])\n",
    "    X = identity_block(X, 3, [64, 64, 128])\n",
    "    \n",
    "    X = convolutional_block(X, 3, [128, 128, 256])\n",
    "    X = identity_block(X, 3, [128, 128, 256])\n",
    "    X = identity_block(X, 3, [128, 128, 256])\n",
    "    \n",
    "    X = convolutional_block(X, 5, [256, 256, 512])\n",
    "    X = identity_block(X, 3, [256, 256, 512])\n",
    "    X = identity_block(X, 3, [256, 256, 512])\n",
    "    \n",
    "    X = convolutional_block(X, 3, [512, 512, 1024])\n",
    "    X = identity_block(X, 3, [512, 512, 1024])\n",
    "    X = identity_block(X, 3, [512, 512, 1024])\n",
    "    \n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    output = Dense(num_classes, activation='softmax')(X)\n",
    "\n",
    "    #Model Initialization\n",
    "    model = Model(inputs = X_input, outputs = output, name = \"ResNet\")\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(input_shape = (32, 32, 3), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 30, 30, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 30, 30, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 30, 30, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 29, 29, 32)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 15, 64)   2112        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 15, 15, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 15, 15, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 15, 15, 64)   102464      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 15, 15, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 15, 15, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 128)  4224        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 128)  8320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 15, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 15, 15, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 15, 15, 128)  0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 15, 15, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 64)   8256        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 15, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 128)  8320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 15, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 128)  0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 64)   8256        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 15, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 128)  8320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 15, 15, 128)  0           batch_normalization_11[0][0]     \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 128)    16512       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 256)    33024       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    33024       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 256)    0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 128)    32896       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 128)    147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 256)    33024       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 256)    0           batch_normalization_18[0][0]     \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 128)    32896       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 128)    512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 256)    33024       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 4, 256)    65792       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 256)    1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 256)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 4, 256)    1638656     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 4, 256)    1024        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 256)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 512)    131584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 4, 512)    131584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 4, 512)    2048        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 4, 512)    2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 512)    0           batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 256)    131328      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 256)    1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 256)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 256)    590080      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 256)    1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 256)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 512)    131584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 512)    2048        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 512)    0           batch_normalization_28[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 256)    131328      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 256)    1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 256)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 256)    590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 256)    1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 256)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 512)    131584      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 512)    2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 512)    0           batch_normalization_31[0][0]     \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 2, 2, 512)    262656      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 2, 2, 512)    2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 512)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 2, 2, 512)    2359808     activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 2, 2, 512)    2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 512)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 2, 2, 1024)   525312      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 2, 2, 1024)   525312      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 2, 2, 1024)   4096        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 2, 2, 1024)   4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_35[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 2, 2, 512)    524800      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 2, 2, 512)    2048        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 512)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 2, 2, 512)    2359808     activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 2, 2, 512)    2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 2, 512)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 2, 2, 1024)   525312      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 2, 2, 1024)   4096        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_38[0][0]     \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 2, 2, 512)    524800      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 2, 2, 512)    2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 2, 512)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 2, 2, 512)    2359808     activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 2, 2, 512)    2048        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 2, 512)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 2, 2, 1024)   525312      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 2, 2, 1024)   4096        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 1024)   0           batch_normalization_41[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           40970       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,143,562\n",
      "Trainable params: 15,116,618\n",
      "Non-trainable params: 26,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    R = image[:1024]\n",
    "    G = image[1024:2048]\n",
    "    B = image[2048:]\n",
    "    \n",
    "    r = R.reshape((32, 32))\n",
    "    g = G.reshape((32, 32))\n",
    "    b = B.reshape((32, 32))\n",
    "    \n",
    "    img = np.dstack((r, g, b))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_data(dataset):\n",
    "    images = []\n",
    "    for image in dataset:\n",
    "        img = process_image(image)\n",
    "        images.append(img)\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 40s 4ms/step - loss: 3.7368 - accuracy: 0.2708\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 2.2514 - accuracy: 0.3755\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 1.7005 - accuracy: 0.4464\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 1.4381 - accuracy: 0.4940\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 1.3083 - accuracy: 0.5429\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 1.1156 - accuracy: 0.6082\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.9761 - accuracy: 0.6541\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.8457 - accuracy: 0.7036 1s - loss: 0\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.7063 - accuracy: 0.7522\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.6020 - accuracy: 0.7924\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.5022 - accuracy: 0.8234\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.4001 - accuracy: 0.8643\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.3220 - accuracy: 0.8874\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.2808 - accuracy: 0.9022\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.2282 - accuracy: 0.9194\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.2399 - accuracy: 0.9136\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.2175 - accuracy: 0.9248\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.1757 - accuracy: 0.9404\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.1624 - accuracy: 0.9428\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1569 - accuracy: 0.9459\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 1.1237 - accuracy: 0.6200\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.7247 - accuracy: 0.7490\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.4821 - accuracy: 0.8382\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.3439 - accuracy: 0.8767\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.2582 - accuracy: 0.9116\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.2060 - accuracy: 0.9311\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1872 - accuracy: 0.9397\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1356 - accuracy: 0.9532\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.1324 - accuracy: 0.9519\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1249 - accuracy: 0.9580\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1500 - accuracy: 0.9532\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1223 - accuracy: 0.9601\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.0940 - accuracy: 0.9684\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.0716 - accuracy: 0.9748\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.0783 - accuracy: 0.9727\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.0870 - accuracy: 0.9688\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 34s 3ms/step - loss: 0.0921 - accuracy: 0.9694\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.0773 - accuracy: 0.9740\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.0823 - accuracy: 0.9736 1s\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.0705 - accuracy: 0.9755\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.9692 - accuracy: 0.6768\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.5152 - accuracy: 0.8212\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.2840 - accuracy: 0.9042\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1717 - accuracy: 0.9406\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1496 - accuracy: 0.9490\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.1146 - accuracy: 0.9609\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.0890 - accuracy: 0.9725\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.0760 - accuracy: 0.9745\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.0882 - accuracy: 0.9709\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.0626 - accuracy: 0.9807\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 33s 3ms/step - loss: 0.0836 - accuracy: 0.9724\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.0778 - accuracy: 0.9732\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 33s 3ms/step - loss: 0.0576 - accuracy: 0.9817\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 40s 4ms/step - loss: 0.0607 - accuracy: 0.9810 1s - loss: 0.0\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 38s 4ms/step - loss: 0.0574 - accuracy: 0.9814\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0962 - accuracy: 0.9706\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 34s 3ms/step - loss: 0.0769 - accuracy: 0.9750\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 34s 3ms/step - loss: 0.0886 - accuracy: 0.9713\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 34s 3ms/step - loss: 0.0692 - accuracy: 0.9796\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 34s 3ms/step - loss: 0.0536 - accuracy: 0.9833\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 35s 3ms/step - loss: 0.9695 - accuracy: 0.6884\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 40s 4ms/step - loss: 0.4689 - accuracy: 0.8404\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 37s 4ms/step - loss: 0.1989 - accuracy: 0.9330\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.1253 - accuracy: 0.9573\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 35s 4ms/step - loss: 0.1044 - accuracy: 0.9641\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 35s 4ms/step - loss: 0.0642 - accuracy: 0.9777\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 40s 4ms/step - loss: 0.0989 - accuracy: 0.9679\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 41s 4ms/step - loss: 0.0663 - accuracy: 0.9785\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 40s 4ms/step - loss: 0.0576 - accuracy: 0.9807\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 41s 4ms/step - loss: 0.0503 - accuracy: 0.9821\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 38s 4ms/step - loss: 0.0697 - accuracy: 0.9789\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.0455 - accuracy: 0.9849\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0600 - accuracy: 0.9803\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0625 - accuracy: 0.9798\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 41s 4ms/step - loss: 0.0641 - accuracy: 0.9787\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 38s 4ms/step - loss: 0.1608 - accuracy: 0.9596\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0787 - accuracy: 0.9754\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 37s 4ms/step - loss: 0.0434 - accuracy: 0.9875\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 35s 3ms/step - loss: 0.0325 - accuracy: 0.9908\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 37s 4ms/step - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.9109 - accuracy: 0.7181\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 41s 4ms/step - loss: 0.3904 - accuracy: 0.8690\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 40s 4ms/step - loss: 0.1594 - accuracy: 0.9487\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 41s 4ms/step - loss: 0.0731 - accuracy: 0.9760\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 41s 4ms/step - loss: 0.0704 - accuracy: 0.9768\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 42s 4ms/step - loss: 0.0792 - accuracy: 0.9739\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.0713 - accuracy: 0.9754\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.0747 - accuracy: 0.9744\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.0688 - accuracy: 0.9779\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.0637 - accuracy: 0.9802\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.0962 - accuracy: 0.9691\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.1224 - accuracy: 0.9670\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.0173 - accuracy: 0.9944\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.0448 - accuracy: 0.9871\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 43s 4ms/step - loss: 0.0707 - accuracy: 0.9762\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 45s 4ms/step - loss: 0.0357 - accuracy: 0.9895\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 44s 4ms/step - loss: 0.0200 - accuracy: 0.9934\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 42s 4ms/step - loss: 0.0178 - accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "        batch_name = 'cifar-10-batches-py/data_batch_' + str(i+1)\n",
    "        data_batch_i = unpickle(batch_name)\n",
    "        data_ = data_batch_i[b'data']\n",
    "        labels = data_batch_i[b'labels']\n",
    "        \n",
    "        x_batch = final_data(data_)\n",
    "        y_batch = labels\n",
    "        y_batch = to_categorical(y_batch, num_classes = 10)\n",
    "        \n",
    "        model.fit(x_batch, y_batch, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = unpickle('cifar-10-batches-py/test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_batch[b'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_batch[b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = final_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 32, 32, 3), (10000, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 767us/step\n"
     ]
    }
   ],
   "source": [
    "hist = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7036216952323913, 0.7251999974250793]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
